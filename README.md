# Budget-Constrained Traveling Salesman Problem: a Cooperative Multi-Agent Reinforcement Learning Approach

This GitHub repository contains all the code and reference paper for the research titled "Budget-Constrained Traveling Salesman Problem: a Cooperative Multi-Agent Reinforcement Learning Approach."

## Code Overview

The code includes the following components:

- **Sensor Network**: Environment where agents are trained.
- **Agent**: Agent used to interact with the environment.
- **P-MARL Algorithm**: Implementation of the Cooperative Multi-Agent Reinforcement Learning approach.
- **DQ Network in PyTorch**: Deep Q-Network implementation.
- **Utility Files**: Various utility files such as experiment buffer class, training loop, etc.

## How to Use

1. Clone the repository to your local machine.
2. Install the necessary dependencies (e.g., PyTorch).
3. Run the desired scripts for training or evaluation.

## Reference Paper

[1] Haversine formula. https://en.wikipedia.org/wiki/Haversine formula. 
[2] Miller–tucker–zemlin (mtz) subtour elimination constraint. https://how- to.aimms.com/Articles/332/332-Miller-Tucker-Zemlin-formulation.html. 
[3] Traveling salesman tour of us capital cities. https://www.math.uwaterloo.ca/tsp/data/usa/index.html.
[4] A better approximation algorithm for the budget prize collecting tree problem. Operations Research Letters, 32(4):316–319, 2004.
5] K. Arulkumaran, M. P. Deisenroth, M. Brundage, and A. A. Bharath. Deep reinforcement learning: A brief survey. IEEE Signal Processing Magazine, 34(6):26–38, November 2017.
[6] I.Bello,H.Pham,Q.V.Le,M.Norouzi,andS.Bengio.Neuralcombina- torial optimization with reinforcement learning. CoRR, abs/1611.09940, 2016.
[7] L. Busoniu, R. Babuska, and B. De Schutter. A comprehensive survey of multiagent reinforcement learning. IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews), 38(2):156– 172, 2008. 
[8] B. Chandra Mohan and R. Baskaran. A survey: Ant colony optimiza- tion based recent research and implementation on several engineering domain. Expert Systems with Applications, 39(4):4618–4627, 2012. 
[9] Omar Cheikhrouhou and Ines Khoufi. A comprehensive survey on the multiple traveling salesman problem: Applications, approaches and taxonomy. Computer Science Review, 40, may 2021. 
[10]  S. Dara and P. Tumma. Feature extraction by using deep learning: A survey. In 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), pages 1795–1801. 
[11]  Mario Di Francesco, Sajal K. Das, and Giuseppe Anastasi. Data collection in wireless sensor networks with mobile elements: A survey. 8(1), 2011. 
[12]  O. Dogan and A. Alkaya. A novel method for prize collecting traveling salesman problem with time windows. In Intelligent and Fuzzy Techniques for Emerging Conditions and Digital Transformation. Springer International Publishing, 2022. 
[13]  MarcoDorigoandLucaMariaGambardella.Astudyofsomeproperties of ant-q. In Hans-Michael et al. Voigt, editor, Parallel Problem Solving from Nature — PPSN IV, 1996. 
[14]  I. Drori et al. Learning to solve combinatorial optimization problems on real-world graphs in linear time. In 19th IEEE International Conference on Machine Learning and Applications (ICMLA), pages 19–24, 2020. 
[15]  L. Gambardella and M. Dorigo. Ant-q: A reinforcement learning approach to the traveling salesman problem. In ICML, 1995. 
[16]  L. C. Garaffa, M. Basso, A. A. Konzen, and E. P. de Freitas. Rein- forcement learning for mobile robotics exploration: A survey. IEEE Transactions on Neural Networks and Learning Systems, 34(8):3796– 3810, 2023. 
[17]  Y. Gu, F. Ren, Y. Ji, and J. Li. The evolution of sink mobility man- agement in wireless sensor networks: A survey. IEEE Communications Surveys & Tutorials, 18(1):507–524, 2016. 
[18]  S. Guo, C. Wang, and Y. Yang. Joint mobile data gathering and energy provisioning in wireless rechargeable sensor networks. IEEE Transactions on Mobile Computing, 13(12):2836–2852, 2014. 
[19]  A.GuezH.VanHasseltandD.Silver.Deepreinforcementlearningwith double q-learning. In 30th AAAI Conference on Artificial Intelligence, 2016. 
[20]  J. Hua, L. Zeng, G. Li, and Z. Ju. Learning for a robot: Deep reinforcement learning, imitation learning, transfer learning. Sensors, 21(4), 2021. 
[21]  H. Huang, A. V. Savkin, M. Ding, and C. Huang. Mobile robots in wireless sensor networks: A survey on tasks. Computer Networks, 148:1–19, 2019. 
[22]  D. Kim, L. Xue, D. Li, Y. Zhu, W. Wang, and A. O. Tokuta. On theoretical trajectory planning of multiple drones to minimize latency in search-and-reconnaissance operations. IEEE Transactions on Mobile Computing, 16(11):3156–3166, 2017. 
[23]  J.Kober,J.A.Bagnell,andJ.Peters.Reinforcementlearninginrobotics: A survey. 32(11), 2013. 
[24]  Gilbert Laporte. The traveling salesman problem: An overview of the exact and approximate algorithms. European Journal of Operational Research, 59:231–247, 1992. 
[25]  Michael L. Littman. Value-function reinforcement learning in markov games. Cognitive Systems Research, 2(1):55–66, 2001. 
[26]  M. Ma, Y. Yang, and M. Zhao. Tour planning for mobile data- gathering mechanisms in wireless sensor networks. IEEE Transactions on Vehicular Technology, 62(4):1472–1483, 2013. 
[27]  N. Mazyavkina, S. Sviridov, S. Ivanov, and E. Burnaev. Reinforcement learning for combinatorial optimization: A survey. Computers Opera- tions Research, 134, 2021. 
[28]  M. Nazari, A. Oroojlooy, L. Snyder, and M. Takac. Reinforcement learning for solving the vehicle routing problem. In S. Bengio et al., editor, Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.
[29] S. Niu, Y. Liu, J. Wang, and H. Song. A decade survey of transfer 
learning (2010–2020). IEEE Transactions on Artificial Intelligence, 1(2):151–166, 2020.
[30] A. Paul, D. Freund, A. Ferber, D. B. Shmoys, and D. P. Williamson. Prize-collecting tsp with a budget constraint. In 25th Annual European  Symposium on Algorithms (ESA 2017).
[31] J. Ruiz, C. Gonzalez, Y. Chen, and B. Tang. Prize-collecting traveling salesman problem: a reinforcement learning approach. In Proc. of IEEE  ICC, 2023.
[32] H.Salarian,K.W.Chin,andF.Naghdy.Anenergy-efficientmobile-sink  path selection strategy for wireless sensor networks. IEEE Transactions on Vehicular Technology, 63(5):2407–2419, 2014.
[33] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini. The graph neural network model. IEEE Transactions on Neural Networks, 20:61–80, 2009.
[34] T. Schaul, J. Quan, I. Antonoglou, and D. Silver. Prioritized experience replay, 2016.
[35] PadminiR.Sokkappa.Thecost-constrainedtravelingsalesmanproblem, 1991. Ph.D. Thesis, Stanford University.
[36] R. S. Sutton and A. G. Barto. Reinforcement Learning, An Introduction. The MIT Press, 2020.
[37] Ming Tan. Multi-agent reinforcement learning: independent vs. coop- erative agents, page 487–494. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1997.
[38] P. Vansteenwegen, W. Souffriau, and D. V. Oudheusden. Orienteering problem: A survey of recent variants, solution approaches and applica- tions. European Journal of Operational Research, 255(2):315 – 332, 2016. 
[39] C. Wang, S. Guo, and Y. Yang. An optimization framework for mobile data collection in energy-harvesting wireless sensor networks. IEEE Transactions on Mobile Computing, 15(12):2969–2986, 2016. 
[40] Y.-C. Wang and K-C. Chen. Efficient path planning for a mobile sink to reliably gather data from sensors with diverse sensing rates and limited buffers. IEEE Transactions on Mobile Computing, 18(7):1527–1540, 2019. 
[41] Y. Wei and R. Zheng. Informative path planning for mobile sensing with reinforcement learning. In IEEE INFOCOM 2020, 2020. 
[42] Y. Wei and R. Zheng. A reinforcement learning framework for efficient informative sensing. IEEE Transactions on Mobile Computing, 21(7):2306–2317, 2022. 
[43] K. Xu, W. Hu, J. Leskovec, and S. Jegelka. How powerful are graph neural networks? CoRR, abs/1810.00826, 2018. 
[44] L. Xue, D. Kim, Y. Zhu, D. Li, W. Wang, and A. O. Tokuta. Multiple heterogeneous data ferry trajectory planning in wireless sensor networks. In IEEE INFOCOM 2014, pages 2274–2282. 
[45] Y. Yang and M. Zhao. Optimization-based distributed algorithms for mobile data gathering in wireless sensor networks. IEEE Transactions on Mobile Computing, 11(10):1464–1477, 2012. 
[46] R. Zhang, C. Zhang, Z. Cao, W. Song, P. S. Tan, J. Zhang, B. Wen, and J. Dauwels. Learning to solve multiple-tsp with time window and rejections via deep reinforcement learning. IEEE Transactions on Intelligent Transportation Systems, 2022. 

## License

This project is licensed under the MIT License - see the LICENSE.md file for details.

## Acknowledgements

I extend my gratitude to my thesis advisor, Dr. Tang, for their consistent and thorough collaboration, and for imparting valuable insights into the research process. Additionally, I would like to express appreciation to Dr. Chen and Dr. Moosavi for their contributions as members of my committee and their dedication. Special thanks to NSF Grant 2240517 for their grant, which supported this research.![image](https://github.com/Vincentmak1994/Vincentmak1994-Multi-agent-reinforcement-learning-in-TSP/assets/29557346/b6770b63-9b98-4f64-b224-89ebfb5e9357)


